{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de01df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import hiplot as hip\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, RationalQuadratic, Matern, ExpSineSquared,DotProduct\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "from yellowbrick.features import ParallelCoordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "209adfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Input\n",
    "\n",
    "df1 = pd.read_csv('Input.csv')\n",
    "\n",
    "df1.rename(columns = {'TLI':'InletLiquidTemperature', 'TAI':'InletAirTemperature'\n",
    "                   , 'H':'PackedBedHeight' , 'D':'PackedBedDiameter', 'ML':'LiquidMassFlow'\n",
    "                   , 'MA':'AirMassFlow', 'EPS':'PackedBedPorosity'}, inplace = True)\n",
    "\n",
    "X = df1.to_numpy() #Input\n",
    "\n",
    "#Reading Output\n",
    "\n",
    "df2 = pd.read_csv('Output.csv')\n",
    "\n",
    "df2.rename(columns = {'TLO':'OutletLiquidTemperature', 'TAO':'OutletAirTemperature'}, inplace = True)\n",
    "\n",
    "Y = df2.to_numpy() \n",
    "\n",
    "df3 = pd.concat([df1, df2], axis=1, join=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72dd7c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inlet Liquid Temperature</th>\n",
       "      <th>Inlet Air Temperature</th>\n",
       "      <th>Packed Bed Height</th>\n",
       "      <th>Packed Bed Diameter</th>\n",
       "      <th>Liquid Mass Flow</th>\n",
       "      <th>Air Mass Flow</th>\n",
       "      <th>Packed Bed Porosity</th>\n",
       "      <th>Outlet Liquid Temperature</th>\n",
       "      <th>Outlet Air Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45678.000000</td>\n",
       "      <td>45678.000000</td>\n",
       "      <td>45678.000000</td>\n",
       "      <td>45678.000000</td>\n",
       "      <td>45678.000000</td>\n",
       "      <td>45678.000000</td>\n",
       "      <td>45678.000000</td>\n",
       "      <td>45678.000000</td>\n",
       "      <td>45678.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.854543</td>\n",
       "      <td>59.934726</td>\n",
       "      <td>0.745895</td>\n",
       "      <td>0.233062</td>\n",
       "      <td>0.034981</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>0.850460</td>\n",
       "      <td>38.468124</td>\n",
       "      <td>34.854467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.867972</td>\n",
       "      <td>7.542225</td>\n",
       "      <td>0.249969</td>\n",
       "      <td>0.077232</td>\n",
       "      <td>0.009854</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.049716</td>\n",
       "      <td>10.242637</td>\n",
       "      <td>5.487013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>25.269364</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>20.645000</td>\n",
       "      <td>21.518000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>31.003000</td>\n",
       "      <td>31.186000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>37.719000</td>\n",
       "      <td>35.121000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>43.639000</td>\n",
       "      <td>38.713750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>98.411859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>89.240000</td>\n",
       "      <td>80.423000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Inlet Liquid Temperature  Inlet Air Temperature  Packed Bed Height  \\\n",
       "count              45678.000000           45678.000000       45678.000000   \n",
       "mean                  29.854543              59.934726           0.745895   \n",
       "std                    6.867972               7.542225           0.249969   \n",
       "min                   20.000000              25.269364           0.500000   \n",
       "25%                   24.000000              54.000000           0.500000   \n",
       "50%                   28.000000              58.000000           0.500000   \n",
       "75%                   36.000000              66.000000           1.000000   \n",
       "max                   40.000000              98.411859           1.000000   \n",
       "\n",
       "       Packed Bed Diameter  Liquid Mass Flow  Air Mass Flow  \\\n",
       "count         45678.000000      45678.000000   45678.000000   \n",
       "mean              0.233062          0.034981       0.003717   \n",
       "std               0.077232          0.009854       0.002150   \n",
       "min               0.140000          0.020000       0.000340   \n",
       "25%               0.150000          0.026000       0.002000   \n",
       "50%               0.250000          0.034000       0.003000   \n",
       "75%               0.250000          0.042000       0.005000   \n",
       "max               0.350000          0.054000       0.008000   \n",
       "\n",
       "       Packed Bed Porosity  Outlet Liquid Temperature  Outlet Air Temperature  \n",
       "count         45678.000000               45678.000000            45678.000000  \n",
       "mean              0.850460                  38.468124               34.854467  \n",
       "std               0.049716                  10.242637                5.487013  \n",
       "min               0.800000                  20.645000               21.518000  \n",
       "25%               0.800000                  31.003000               31.186000  \n",
       "50%               0.878000                  37.719000               35.121000  \n",
       "75%               0.900000                  43.639000               38.713750  \n",
       "max               0.900000                  89.240000               80.423000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.read_csv('Whole.csv')\n",
    "\n",
    "df4.rename(columns = {'TLI':'Inlet Liquid Temperature', 'TAI':'Inlet Air Temperature'\n",
    "                   , 'H':'Packed Bed Height' , 'D':'Packed Bed Diameter', 'ML':'Liquid Mass Flow'\n",
    "                   , 'MA':'Air Mass Flow', 'EPS':'Packed Bed Porosity','TLO':'Outlet Liquid Temperature', 'TAO':'Outlet Air Temperature'}, inplace = True)\n",
    "\n",
    "Whole = df4.to_numpy() #Input\n",
    "\n",
    "\n",
    "df4.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "252fd812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45678 entries, 0 to 45677\n",
      "Data columns (total 9 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Inlet Liquid Temperature   45678 non-null  float64\n",
      " 1   Inlet Air Temperature      45678 non-null  float64\n",
      " 2   Packed Bed Height          45678 non-null  float64\n",
      " 3   Packed Bed Diameter        45678 non-null  float64\n",
      " 4   Liquid Mass Flow           45678 non-null  float64\n",
      " 5   Air Mass Flow              45678 non-null  float64\n",
      " 6   Packed Bed Porosity        45678 non-null  float64\n",
      " 7   Outlet Liquid Temperature  45678 non-null  float64\n",
      " 8   Outlet Air Temperature     45678 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "df4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00ebde24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OutletLiquidTemperature</th>\n",
       "      <th>OutletAirTemperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.730</td>\n",
       "      <td>31.457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.222</td>\n",
       "      <td>33.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.603</td>\n",
       "      <td>34.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.904</td>\n",
       "      <td>35.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.574</td>\n",
       "      <td>31.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45673</th>\n",
       "      <td>23.381</td>\n",
       "      <td>22.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45674</th>\n",
       "      <td>23.366</td>\n",
       "      <td>22.615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45675</th>\n",
       "      <td>23.381</td>\n",
       "      <td>22.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45676</th>\n",
       "      <td>23.366</td>\n",
       "      <td>22.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45677</th>\n",
       "      <td>23.361</td>\n",
       "      <td>22.825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45678 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       OutletLiquidTemperature  OutletAirTemperature\n",
       "0                       21.730                31.457\n",
       "1                       23.222                33.284\n",
       "2                       24.603                34.375\n",
       "3                       25.904                35.166\n",
       "4                       21.574                31.440\n",
       "...                        ...                   ...\n",
       "45673                   23.381                22.521\n",
       "45674                   23.366                22.615\n",
       "45675                   23.381                22.692\n",
       "45676                   23.366                22.752\n",
       "45677                   23.361                22.825\n",
       "\n",
       "[45678 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cc5b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "# Best linear estimation\n",
    "\n",
    "reg = MultiOutputRegressor(LinearRegression()).fit(X, Y)\n",
    "linear_score=reg.score(X, Y)\n",
    "print(linear_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d404eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsize=0.8\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=trainsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6597ea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "Y0_train = Y_train[:,0]\n",
    "Y1_train = Y_train[:,1]\n",
    "Y0_test = Y_test[:,0]\n",
    "Y1_test = Y_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17a9faf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Arr = []\n",
    "Arr_df = pd.DataFrame(Arr,columns = ['Train Size','First layer','Second layer','Learning Rate',\n",
    "                                     'Solver','Activation','MLP Training','MLP Test'])\n",
    "for i in [0.001,0.01,0.1]:\n",
    "    for j in ['sgd','lbfgs','adam']:\n",
    "        for k in ['relu','tanh','logistic','identity']:\n",
    "            for l in [0.0001,0.001,0.01,0.1]:\n",
    "                for m in [1000,2000,4000,8000]:\n",
    "                    mlp = MultiOutputRegressor(MLPRegressor(hidden_layer_sizes=(6,3), max_iter=2000,\n",
    "                                solver=j, verbose=0, tol=1e-5,activation = k,learning_rate_init=i,alpha=l))\n",
    "                    mlp.fit(X_train_scaled, Y_train)\n",
    "                    Arr.append([trainsize, i,j,k,l,m,mlp.score(X_train_scaled, Y_train),mlp.score(X_test_scaled, Y_test)])\n",
    "                    print(i,j,k,l,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adc5793",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_Result = pd.DataFrame(Arr, columns = ['Train Size','Learning Rate','Solver ','Activation',\n",
    "                                     'Alpha','Max Iteration','MLP Training','MLP Test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6ec559",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NN_Result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb97dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  \n",
    "filepath = Path('MLP_Hyper.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "NN_Result.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17685ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_Result.loc[NN_Result['MLP Test'] >= 0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e86487",
   "metadata": {},
   "outputs": [],
   "source": [
    "Arr1 = []\n",
    "Arr_df = pd.DataFrame(Arr1,columns = ['Train Size','First layer','Second layer','Third layer'\n",
    "                                      ,'MLP0 Training','MLP0 Test','MLP1 Training','MLP1 Test'])\n",
    "for i in range(1,10):\n",
    "    for j in range(1,10):\n",
    "        for k in range(1,10):\n",
    "            \n",
    "            mlp0 = MLPRegressor(hidden_layer_sizes=(i,j,k), max_iter=200, alpha=1,\n",
    "                    solver='sgd', verbose=0, tol=1e-5,activation = 'relu',learning_rate_init=.01)\n",
    "            mlp1 = MLPRegressor(hidden_layer_sizes=(i,j,k), max_iter=200, alpha=1,\n",
    "                    solver='sgd', verbose=0, tol=1e-5,activation = 'relu',learning_rate_init=.01)\n",
    "            mlp0.fit(X_train_scaled, Y0_train)\n",
    "            mlp1.fit(X_train_scaled, Y1_train)\n",
    "            Arr1.append([trainsize, i,j,k,mlp0.score(X_train_scaled, Y0_train),mlp0.score(X_test_scaled, Y0_test)\n",
    "                         ,mlp1.score(X_train_scaled, Y1_train),mlp0.score(X_test_scaled, Y1_test)])\n",
    "            print(i,j,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce27a957",
   "metadata": {},
   "outputs": [],
   "source": [
    "Arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36618b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb03186",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Arr = []\n",
    "Arr_df = pd.DataFrame(Arr,columns = ['Train Size','First layer','Second layer','Third layer','MLP Training','MLP Test'])\n",
    "time_start = time.time()\n",
    "for i in range(1,10):\n",
    "    for j in range(1,10):\n",
    "        for k in range(1,10):\n",
    "            mlp = MultiOutputRegressor(MLPRegressor(hidden_layer_sizes=(i,j,k), max_iter=10000, alpha=1,\n",
    "                    solver='lbfgs', verbose=0, tol=1e-5,activation = 'relu',learning_rate_init=.01),n_jobs=40)\n",
    "            mlp.fit(X_train_scaled, Y_train)\n",
    "            Arr.append([trainsize, i,j,k,mlp.score(X_train_scaled, Y_train),mlp.score(X_test_scaled, Y_test)])\n",
    "            print(i,j,k,mlp.score(X_train_scaled, Y_train),mlp.score(X_test_scaled, Y_test))\n",
    "    \n",
    "time_elapsed = (time.time() - time_start)\n",
    "print('time_elapsed=', time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e607176",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_Result_3Layers = pd.DataFrame(Arr, columns = ['Train Size','First layer','Second layer',\n",
    "                                                 'Third layer','MLP Training','MLP Test'])\n",
    "from pathlib import Path  \n",
    "filepath = Path('NN_Result_3Layers.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "NN_Result_3Layers.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e73dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921f819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stand_scaler_obj = StandardScaler()\n",
    "my_stand_scaler_obj.fit(X_train)\n",
    "\n",
    "# rescale the training data\n",
    "X_stand_scaler = my_stand_scaler_obj.transform(X)\n",
    "\n",
    "# rescale the training data\n",
    "X_train_stand_scaler = my_stand_scaler_obj.transform(X_train)\n",
    "\n",
    "# also, rescale the training data\n",
    "X_test_stand_scaler = my_stand_scaler_obj.transform(X_test)\n",
    "\n",
    "\n",
    "print(my_stand_scaler_obj.mean_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae847ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KRR  = KernelRidge(alpha=.01, kernel='rbf')\n",
    "MLP1 = MLPRegressor(hidden_layer_sizes=(3,3), max_iter=10000, alpha=1,\n",
    "                    solver='lbfgs', verbose=0, tol=1e-5,activation = 'relu',learning_rate_init=.01)\n",
    "MLP2 = MLPRegressor(hidden_layer_sizes=(6,6), max_iter=10000, alpha=1,\n",
    "                    solver='lbfgs', verbose=0, tol=1e-5,activation = 'relu',learning_rate_init=.01)\n",
    "MLP3 = MLPRegressor(hidden_layer_sizes=(9,9), max_iter=10000, alpha=1,\n",
    "                    solver='lbfgs', verbose=0, tol=1e-5,activation = 'relu',learning_rate_init=.01)\n",
    "MLP4 = MLPRegressor(hidden_layer_sizes=(3,3,3), max_iter=10000, alpha=1,\n",
    "                    solver='lbfgs', verbose=0, tol=1e-5,activation = 'relu',learning_rate_init=.01)\n",
    "MLP5 = MLPRegressor(hidden_layer_sizes=(6,6,6), max_iter=10000, alpha=1,\n",
    "                    solver='lbfgs', verbose=0, tol=1e-5,activation = 'relu',learning_rate_init=.01)\n",
    "MLP6 = MLPRegressor(hidden_layer_sizes=(9,9,9), max_iter=10000, alpha=1,\n",
    "                    solver='lbfgs', verbose=0, tol=1e-5,activation = 'relu',learning_rate_init=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e33266b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a8c4ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(MLP1,\n",
    "                                                        X_stand_scaler, Y,\n",
    "                                                        cv = 10,\n",
    "                                                        scoring=\"r2\", \n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "# Means and standard deviations of training set scores\n",
    "train_mean1 = np.mean(train_scores, axis=1).reshape(-1,1)\n",
    "# Means and standard deviations of test set scores\n",
    "test_mean1 = np.mean(test_scores, axis=1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e8ad29",
   "metadata": {},
   "outputs": [],
   "source": [
    "Arr=np.linspace(0.1, 0.9, 51).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f06377",
   "metadata": {},
   "outputs": [],
   "source": [
    "Arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496e36af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Arr=np.append(Arr,train_mean1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db12c4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Arr=np.append(Arr,test_mean1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdfed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "Arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec27a6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Reading Input\n",
    "df1 = pd.read_csv('Input4.csv')\n",
    "df1.rename(columns = {'TLI':'InletLiquidTemperature', 'TAI':'InletAirTemperature'\n",
    "                   , 'H':'PackedBedHeight' , 'D':'PackedBedDiameter', 'ML':'LiquidMassFlow'\n",
    "                   , 'MA':'AirMassFlow', 'EPS':'PackedBedPorosity'}, inplace = True)\n",
    "\n",
    "X = df1.to_numpy() #Input\n",
    "#Reading Output\n",
    "df2 = pd.read_csv('Output4.csv')\n",
    "df2.rename(columns = {'TLO':'OutletLiquidTemperature', 'TAO':'OutletAirTemperature'}, inplace = True)\n",
    "Y = df2.to_numpy() \n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "# Best linear estimation\n",
    "\n",
    "reg = MultiOutputRegressor(LinearRegression()).fit(X, Y)\n",
    "linear_score=reg.score(X, Y)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1)\n",
    "# transform data\n",
    "my_stand_scaler_obj = StandardScaler()\n",
    "my_stand_scaler_obj.fit(X_train)\n",
    "\n",
    "# rescale the training data\n",
    "X_stand_scaler = my_stand_scaler_obj.transform(X)\n",
    "\n",
    "# rescale the training data\n",
    "X_train_stand_scaler = my_stand_scaler_obj.transform(X_train)\n",
    "\n",
    "# also, rescale the training data\n",
    "X_test_stand_scaler = my_stand_scaler_obj.transform(X_test)\n",
    "\n",
    "Arr=[]\n",
    "\n",
    "########################################################################################################################################################\n",
    "\n",
    "MLP1 = MLPRegressor(hidden_layer_sizes=(3,3), max_iter=40000, alpha=1,solver='lbfgs', verbose=0, tol=1e-5,activation = 'relu',learning_rate_init=.01)\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(MLP1,X_stand_scaler,\n",
    "                                                        Y,cv = 10,scoring=\"neg_mean_squared_error\",\n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "train_sizes1 = train_sizes.reshape(-1,1)\n",
    "\n",
    "Arr= train_sizes1\n",
    "\n",
    "train_mean1 = np.mean(train_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "test_mean1 = np.mean(test_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "print(1111111111111111111111111111111111111111111111111111111111)\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(MLP1,X_stand_scaler,\n",
    "                                                        Y,cv = 10,scoring=\"r2\",\n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "train_mean1 = np.mean(train_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "test_mean1 = np.mean(test_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "print(2222222222222222222222222222222222222222222222222222222222)\n",
    "\n",
    "########################################################################################################################################################\n",
    "\n",
    "MLP2 = MLPRegressor(hidden_layer_sizes=(3,6), max_iter=40000, alpha=1,solver='lbfgs', verbose=0, tol=1e-5,activation = 'relu',learning_rate_init=.01)\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(MLP2,X_stand_scaler,\n",
    "                                                        Y,cv = 10,scoring=\"neg_mean_squared_error\",\n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "train_mean1 = np.mean(train_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "test_mean1 = np.mean(test_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "print(1111111111111111111111111111111111111111111111111111111111)\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(MLP2,X_stand_scaler,\n",
    "                                                        Y,cv = 10,scoring=\"r2\",\n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "train_mean1 = np.mean(train_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "test_mean1 = np.mean(test_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "print(2222222222222222222222222222222222222222222222222222222222)\n",
    "\n",
    "########################################################################################################################################################\n",
    "\n",
    "MLP3 = MLPRegressor(hidden_layer_sizes=(6,3), max_iter=40000, alpha=1,solver='lbfgs', verbose=0, tol=1e-5,activation = 'relu',learning_rate_init=.01)\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(MLP3,X_stand_scaler,\n",
    "                                                        Y,cv = 10,scoring=\"neg_mean_squared_error\",\n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "train_mean1 = np.mean(train_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "test_mean1 = np.mean(test_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "print(1111111111111111111111111111111111111111111111111111111111)\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(MLP3,X_stand_scaler,\n",
    "                                                        Y,cv = 10,scoring=\"r2\",\n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "train_mean1 = np.mean(train_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "test_mean1 = np.mean(test_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "print(2222222222222222222222222222222222222222222222222222222222)\n",
    "\n",
    "########################################################################################################################################################\n",
    "\n",
    "MLP4 = MLPRegressor(hidden_layer_sizes=(3,3,3), max_iter=40000, alpha=1,solver='lbfgs', verbose=0, tol=1e-5,activation = 'relu',learning_rate_init=.01)\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(MLP4,X_stand_scaler,\n",
    "                                                        Y,cv = 10,scoring=\"neg_mean_squared_error\",\n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "train_mean1 = np.mean(train_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "test_mean1 = np.mean(test_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "print(1111111111111111111111111111111111111111111111111111111111)\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(MLP4,X_stand_scaler,\n",
    "                                                        Y,cv = 10,scoring=\"r2\",\n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "train_mean1 = np.mean(train_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "test_mean1 = np.mean(test_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "print(2222222222222222222222222222222222222222222222222222222222)\n",
    "\n",
    "########################################################################################################################################################\n",
    "\n",
    "MLP5 = MLPRegressor(hidden_layer_sizes=(3,3,6), max_iter=40000, alpha=1,solver='lbfgs', verbose=0, tol=1e-5,activation = 'relu',learning_rate_init=.01)\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(MLP5,X_stand_scaler,\n",
    "                                                        Y,cv = 10,scoring=\"neg_mean_squared_error\",\n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "train_mean1 = np.mean(train_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "test_mean1 = np.mean(test_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "print(1111111111111111111111111111111111111111111111111111111111)\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(MLP5,X_stand_scaler,\n",
    "                                                        Y,cv = 10,scoring=\"r2\",\n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "train_mean1 = np.mean(train_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "test_mean1 = np.mean(test_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "print(2222222222222222222222222222222222222222222222222222222222)\n",
    "\n",
    "########################################################################################################################################################\n",
    "\n",
    "MLP6 = MLPRegressor(hidden_layer_sizes=(6,3,3), max_iter=40000, alpha=1,solver='lbfgs', verbose=0, tol=1e-5,activation = 'relu',learning_rate_init=.01)\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(MLP6,X_stand_scaler,\n",
    "                                                        Y,cv = 10,scoring=\"neg_mean_squared_error\",\n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "train_mean1 = np.mean(train_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "test_mean1 = np.mean(test_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "print(1111111111111111111111111111111111111111111111111111111111)\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(MLP6,X_stand_scaler,\n",
    "                                                        Y,cv = 10,scoring=\"r2\",\n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "train_mean1 = np.mean(train_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "test_mean1 = np.mean(test_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "print(2222222222222222222222222222222222222222222222222222222222)\n",
    "\n",
    "########################################################################################################################################################\n",
    "                    \n",
    "MLP7 = MLPRegressor(hidden_layer_sizes=(6,3,6), max_iter=40000, alpha=1,solver='lbfgs', verbose=0, tol=1e-5,activation = 'relu',learning_rate_init=.01)\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(MLP7,X_stand_scaler,\n",
    "                                                        Y,cv = 10,scoring=\"neg_mean_squared_error\",\n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "train_mean1 = np.mean(train_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "test_mean1 = np.mean(test_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "print(1111111111111111111111111111111111111111111111111111111111)\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(MLP7,X_stand_scaler,\n",
    "                                                        Y,cv = 10,scoring=\"r2\",\n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "train_mean1 = np.mean(train_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "test_mean1 = np.mean(test_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "print(2222222222222222222222222222222222222222222222222222222222)\n",
    "\n",
    "########################################################################################################################################################\n",
    "\n",
    "MLP8 = MLPRegressor(hidden_layer_sizes=(6,6,6), max_iter=40000, alpha=1,solver='lbfgs', verbose=0, tol=1e-5,activation = 'relu',learning_rate_init=.01)\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(MLP8,X_stand_scaler,\n",
    "                                                        Y,cv = 10,scoring=\"neg_mean_squared_error\",\n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "train_mean1 = np.mean(train_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "test_mean1 = np.mean(test_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "print(1111111111111111111111111111111111111111111111111111111111)\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(MLP8,X_stand_scaler,\n",
    "                                                        Y,cv = 10,scoring=\"r2\",\n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "train_mean1 = np.mean(train_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "test_mean1 = np.mean(test_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "print(2222222222222222222222222222222222222222222222222222222222)\n",
    "\n",
    "########################################################################################################################################################\n",
    "\n",
    "MLP_8Config = pd.DataFrame(Arr)\n",
    "from pathlib import Path  \n",
    "\n",
    "filepath = Path('MLP_8Config.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "MLP_8Config.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae08c05e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Arr=[]\n",
    "MLP1 = MLPRegressor(hidden_layer_sizes=(3,3), max_iter=40000, alpha=1,solver='lbfgs', verbose=0, tol=1e-5,activation = 'relu',learning_rate_init=.01)\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(MLP1,X_stand_scaler,\n",
    "                                                        Y,cv = 10,scoring=\"neg_mean_squared_error\",\n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "train_sizes1 = train_sizes.reshape(-1,1)\n",
    "\n",
    "Arr= train_sizes1\n",
    "\n",
    "train_mean1 = np.mean(train_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)\n",
    "\n",
    "test_mean1 = np.mean(test_scores, axis=1).reshape(-1,1)\n",
    "\n",
    "Arr=np.append(Arr,train_mean1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422e0505",
   "metadata": {},
   "outputs": [],
   "source": [
    "Arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878baafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Arr1 = pd.DataFrame(Arr)\n",
    "\n",
    "Arr1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094e5576",
   "metadata": {},
   "outputs": [],
   "source": [
    "Arr1.rename(columns = {'0':'Train Size','2':'Test_MSE (3,3)'})\n",
    "\n",
    "Arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa37a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 6))\n",
    "plt.plot(Arr1[0],Arr1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a058cf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp6 = MultiOutputRegressor(MLPRegressor(hidden_layer_sizes=(6,6,6), max_iter=10000, alpha=1,\n",
    "                    solver='lbfgs', verbose=0, tol=1e-5,activation = 'relu',learning_rate_init=.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0117e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "mlp6.fit(X_train_scaled, Y_train)\n",
    "time_elapsed = (time.time()-time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b5f228",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_MLP_Predict=mlp6.predict(X_test_scaled)\n",
    "MSE_MLP=mean_squared_error(Y_test,Y_MLP_Predict)\n",
    "MAE_MLP=mean_absolute_error(Y_test,Y_MLP_Predict)\n",
    "R2_MLP=r2_score(Y_test,Y_MLP_Predict)\n",
    "Score_MLP=mlp6.score(X_test_scaled,Y_test)\n",
    "print(time_elapsed)\n",
    "print(MSE_MLP)\n",
    "print(R2_MLP)\n",
    "print(Score_MLP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba10581",
   "metadata": {},
   "source": [
    "# Saving DNN for Surrogate Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8a8a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3c96a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1 = 'MLP.sav'\n",
    "pickle.dump(mlp, open(filename1, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
